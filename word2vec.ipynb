{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/feedback-prize-2021/train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'Lead':0,\n",
    "          'Position':1,\n",
    "          'Claim':2,\n",
    "          'Concluding Statement':3,\n",
    "          'Evidence':4,\n",
    "          'Counterclaim':5,\n",
    "          'Rebuttal':6\n",
    "          }\n",
    "prev_label = {'Lead':0,\n",
    "          'Position':1,\n",
    "          'Claim':2,\n",
    "          'Concluding Statement':3,\n",
    "          'Evidence':4,\n",
    "          'Counterclaim':5,\n",
    "          'Rebuttal':6,\n",
    "          'Start':7\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = df['predictionstring']\n",
    "sequence = sequence.apply(lambda x: x.split())\n",
    "sequence = sequence.apply(lambda x: list(map(int, x)))\n",
    "sequence\n",
    "df_new = df\n",
    "start, end = [],[]\n",
    "for i in range(len(sequence)):\n",
    "    start.append(sequence[i][0])\n",
    "    end.append(sequence[i][-1])\n",
    "df_new['Start'] = start\n",
    "df_new['End'] = end\n",
    "\n",
    "prev = [7]\n",
    "\n",
    "for i in range(1, len(sequence)):\n",
    "    if df_new['End'][i-1] < df_new['Start'][i]:\n",
    "        prev.append(prev_label[df['discourse_type'][i-1]])\n",
    "    else:\n",
    "        prev.append(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['one_hot'] = prev\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "# Tokenize the text column to get the new column 'tokenized_text'\n",
    "df_new['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in df_new['discourse_text']] \n",
    "print(df_new['tokenized_text'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_new, test_size = 0.2, stratify = df_new['discourse_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['tokenized_text']\n",
    "y_train = train['discourse_type']\n",
    "x_test = test['tokenized_text']\n",
    "y_test = test['discourse_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 200\n",
    "w2v_model = Word2Vec(vector_size = dim)\n",
    "w2v_model.build_vocab(x_train)\n",
    "w2v_model.train(x_train, total_examples = w2v_model.corpus_count, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build word vector for training set by using the average value of all word vectors in the tweet, then scale\n",
    "def wordvector(text, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += w2v_model.wv[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = np.concatenate([wordvector(text, dim) for text in x_train])\n",
    "train_vec = scale(train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.train(x_test, total_examples =  len(x_test), epochs = w2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec = np.concatenate([wordvector(text, dim) for text in x_test])\n",
    "test_vec = scale(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec svm\n",
    "svm_clf = svm.SVC(kernel='rbf',verbose=True)\n",
    "svm_clf.fit(train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = svm_clf.predict(test_vec)\n",
    "svm_accu = metrics.accuracy_score(svm_pred, y_test)\n",
    "svm_f1 = metrics.f1_score(svm_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec random forest\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "rfc_clf = RFC(n_estimators = 100, oob_score = True)\n",
    "rfc_clf.fit(train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc_clf.predict(test_vec)\n",
    "rfc_accu = metrics.accuracy_score(rfc_pred, y_test)\n",
    "rfc_f1 = metrics.f1_score(rfc_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = MinMaxScaler(copy = False)\n",
    "scaler1.fit(train_vec)\n",
    "scaler2 = MinMaxScaler(copy = False)\n",
    "scaler2.fit(test_vec)\n",
    "train_01 = scaler1.transform(train_vec)\n",
    "test_01 = scaler2.transform(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec naivebayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_01,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pred = mnb.predict(test_01)\n",
    "mnb_accu = metrics.accuracy_score(mnb_pred, y_test)\n",
    "mnb_f1 = metrics.f1_score(mnb_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(rfc_pred, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(svm_pred, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(mnb_pred, y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
