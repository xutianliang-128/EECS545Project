{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport sys\nimport numpy as np\nimport argparse\nimport random\nfrom collections import Counter\nfrom scipy.sparse import csr_matrix\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom gensim.utils import simple_preprocess","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:06.54835Z","iopub.execute_input":"2022-03-07T01:13:06.548808Z","iopub.status.idle":"2022-03-07T01:13:06.553881Z","shell.execute_reply.started":"2022-03-07T01:13:06.548777Z","shell.execute_reply":"2022-03-07T01:13:06.553173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ndf = pd.read_csv(\"../input/feedback-prize-2021/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:06.555387Z","iopub.execute_input":"2022-03-07T01:13:06.555911Z","iopub.status.idle":"2022-03-07T01:13:07.868815Z","shell.execute_reply.started":"2022-03-07T01:13:06.555886Z","shell.execute_reply":"2022-03-07T01:13:07.867993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels\nlabels = {'Lead':0,\n          'Position':1,\n          'Claim':2,\n          'Concluding Statement':3,\n          'Evidence':4,\n          'Counterclaim':5,\n          'Rebuttal':6\n          }","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:07.869958Z","iopub.execute_input":"2022-03-07T01:13:07.870204Z","iopub.status.idle":"2022-03-07T01:13:07.876263Z","shell.execute_reply.started":"2022-03-07T01:13:07.870175Z","shell.execute_reply":"2022-03-07T01:13:07.875103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# change labels to int\nlabels_int = []\nfor label in df['discourse_type']:\n    labels_int.append(labels[label])\n\ndf['label'] = labels_int","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:07.87781Z","iopub.execute_input":"2022-03-07T01:13:07.878132Z","iopub.status.idle":"2022-03-07T01:13:08.020467Z","shell.execute_reply.started":"2022-03-07T01:13:07.878093Z","shell.execute_reply":"2022-03-07T01:13:08.019336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize the text column to get the new column 'tokenized_text'\ndf['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in df['discourse_text']] \nprint(df['tokenized_text'].head(10))","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:08.022499Z","iopub.execute_input":"2022-03-07T01:13:08.022697Z","iopub.status.idle":"2022-03-07T01:13:23.9637Z","shell.execute_reply.started":"2022-03-07T01:13:08.022673Z","shell.execute_reply":"2022-03-07T01:13:23.963005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split training and test dataset\nrandom.seed(42)\ntrain, test = train_test_split(df, test_size = 0.2, stratify = df['label'])\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:23.964619Z","iopub.execute_input":"2022-03-07T01:13:23.964797Z","iopub.status.idle":"2022-03-07T01:13:24.391621Z","shell.execute_reply.started":"2022-03-07T01:13:23.964771Z","shell.execute_reply":"2022-03-07T01:13:24.390275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# counter different classes\ncounter_all = {}\nfor i in range(len(train)):\n    label = df['label'][i]\n    text = df['tokenized_text'][i]\n    if label not in counter_all:\n        counter_all[label] = Counter()\n    counter = counter_all[label]\n    # update the counter\n    counter.update(Counter(text))\n# counter_all is the sum counter of different class","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:24.392729Z","iopub.execute_input":"2022-03-07T01:13:24.392901Z","iopub.status.idle":"2022-03-07T01:13:27.909155Z","shell.execute_reply.started":"2022-03-07T01:13:24.392879Z","shell.execute_reply":"2022-03-07T01:13:27.908326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate log-count ratio of NB features\nratios = dict()\nalpha = 0.8 # smoothing parameter\n\n# create a list of all tokens\ntokens = set()\nfor counter in counter_all.values():\n    tokens.update(counter.keys())\ntokens = list(tokens)\nV = len(tokens) # size of all tokens\n\ndic = dict((t, i) for i, t in enumerate(tokens))\n# sum tokens counts for all classes with alpha smoothing\n# 2* because one gets subtracted when q_c is calculate by subtracting p_c\nsum_counts = np.full(V, 2*alpha)\nfor label in counter_all:\n    counter = counter_all[label]\n    for token in tokens:\n        sum_counts[dic[token]] += counter[token]\n        \n# calculate the ratio of different labels\nfor label in counter_all:\n    counter = counter_all[label]\n    p_label = np.full(V, alpha)  # initialize p value with alpha\n\n    # add the tokens counts\n    for token in tokens:\n        p_label[dic[token]] += counter[token]\n\n    # initialize q value\n    q_label = sum_counts - p_label\n\n    # normalize (l1 norm)\n    p_label /= np.linalg.norm(p_label, ord=1)\n    q_label /= np.linalg.norm(q_label, ord=1)\n\n    # p_label = log(p/|p|)\n    p_label = np.log(p_label)\n    # q_label = log(not_p/|not_p|)\n    q_label = np.log(q_label)\n\n    # Subtract log(not_p/|not_p|)\n    ratios[label] = p_label - q_label","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:27.910232Z","iopub.execute_input":"2022-03-07T01:13:27.911318Z","iopub.status.idle":"2022-03-07T01:13:28.715302Z","shell.execute_reply.started":"2022-03-07T01:13:27.911268Z","shell.execute_reply":"2022-03-07T01:13:28.714371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# change training and test data into matrix form\ndef load_data(df,dic,V,ratios):\n    N = len(df)\n    classes = ratios.keys()\n    Y_true = np.zeros(N, dtype=np.int64)\n    \n    # One X (sample) matrix and binary Y (truth) per class\n    X = dict()\n    Y = dict()\n    ratio = dict()\n    indptr = [0]\n    indices = []\n    for c in classes:\n        Y[c] = np.zeros(N, dtype=np.int64)\n        ratio[c] = []\n    \n    for i in range(len(df)):\n        for c in classes:\n            Y[c][i] = int(c == df['label'][i])\n        Y_true[i] = df['label'][i]\n        \n        tokens_count = Counter(df['tokenized_text'][i])\n        for token in tokens_count:\n            if token in dic:\n                index = dic[token]\n                indices.append(index)\n                for c in classes:\n                    ratio[c].append(ratios[c][index])\n        indptr.append(len(indices))\n    \n    for c in classes:\n        X[c] = csr_matrix((ratio[c], indices, indptr), shape=(N, V), dtype=np.float32)\n    \n    return X,Y,Y_true","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:28.717135Z","iopub.execute_input":"2022-03-07T01:13:28.717617Z","iopub.status.idle":"2022-03-07T01:13:28.727267Z","shell.execute_reply.started":"2022-03-07T01:13:28.717579Z","shell.execute_reply":"2022-03-07T01:13:28.72615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train, Y_train_true = load_data(train,dic,V,ratios)\nX_test, Y_test, Y_test_true = load_data(test,dic,V,ratios)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:28.728493Z","iopub.execute_input":"2022-03-07T01:13:28.728725Z","iopub.status.idle":"2022-03-07T01:13:57.096016Z","shell.execute_reply.started":"2022-03-07T01:13:28.728694Z","shell.execute_reply":"2022-03-07T01:13:57.094802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SVM fit\nsvms = dict()\nfor label in ratios.keys():\n    svms[label] = LinearSVC(max_iter = 5000)\n    svms[label].fit(X_train[label], Y_train[label])\n\n# SVM prediction\npreds = dict()\nfor label in ratios.keys():\n    preds[label] = svms[label].decision_function(X_test[label])\n\n# calculate the prediction into true label\npred = np.zeros(len(Y_test_true))\nfor idx in range(len(Y_test_true)):\n    max_score = float('-inf')\n    for label in ratios.keys():\n        if preds[label][idx] > max_score:\n            max_score = preds[label][idx]\n            pred[idx] = label\n            \n# accuarcy\nacc_svm = accuracy_score(Y_test_true, pred)\nprint('NBSVM: %f' % (acc_svm,))","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:13:57.09724Z","iopub.execute_input":"2022-03-07T01:13:57.09743Z","iopub.status.idle":"2022-03-07T01:16:09.53196Z","shell.execute_reply.started":"2022-03-07T01:13:57.097407Z","shell.execute_reply":"2022-03-07T01:16:09.530842Z"},"trusted":true},"execution_count":null,"outputs":[]}]}