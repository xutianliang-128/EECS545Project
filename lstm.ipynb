{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom transformers import BertTokenizer\nimport torch\nfrom torch import nn\nfrom transformers import BertModel\nimport numpy as np\nfrom torch.optim import Adam\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\n\ndf = pd.read_csv(\"/kaggle/input/feedback-prize-2021/train.csv\")\ndf\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T23:51:04.087491Z","iopub.execute_input":"2022-04-26T23:51:04.087741Z","iopub.status.idle":"2022-04-26T23:51:11.68586Z","shell.execute_reply.started":"2022-04-26T23:51:04.087716Z","shell.execute_reply":"2022-04-26T23:51:11.685057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:15.678838Z","iopub.execute_input":"2022-04-26T23:51:15.679108Z","iopub.status.idle":"2022-04-26T23:51:17.641771Z","shell.execute_reply.started":"2022-04-26T23:51:15.679061Z","shell.execute_reply":"2022-04-26T23:51:17.641052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new = df\nfrom gensim.utils import simple_preprocess\n# Tokenize the text column to get the new column 'tokenized_text'\ndf_new['text_without_stopwords'] = df_new['discourse_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (STOPWORDS)]))\ndf_new['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in df_new['text_without_stopwords']] \nprint(df_new['tokenized_text'].head(10))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:19.508575Z","iopub.execute_input":"2022-04-26T23:51:19.509095Z","iopub.status.idle":"2022-04-26T23:51:36.609938Z","shell.execute_reply.started":"2022-04-26T23:51:19.50904Z","shell.execute_reply":"2022-04-26T23:51:36.609242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df_new, test_size = 0.2, stratify = df_new['discourse_type'])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:39.646635Z","iopub.execute_input":"2022-04-26T23:51:39.647301Z","iopub.status.idle":"2022-04-26T23:51:39.943511Z","shell.execute_reply.started":"2022-04-26T23:51:39.647264Z","shell.execute_reply":"2022-04-26T23:51:39.94275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text = train['tokenized_text']\ntrain_lab = train['discourse_type']\ntest_text = test['tokenized_text']\ntest_lab = test['discourse_type']","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:42.131395Z","iopub.execute_input":"2022-04-26T23:51:42.131672Z","iopub.status.idle":"2022-04-26T23:51:42.137188Z","shell.execute_reply.started":"2022-04-26T23:51:42.131641Z","shell.execute_reply":"2022-04-26T23:51:42.136141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nresults = Counter()\ndf['text_without_stopwords'].str.lower().str.split().apply(results.update)\nlen(results.values())","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:44.239487Z","iopub.execute_input":"2022-04-26T23:51:44.239748Z","iopub.status.idle":"2022-04-26T23:51:45.914625Z","shell.execute_reply.started":"2022-04-26T23:51:44.239718Z","shell.execute_reply":"2022-04-26T23:51:45.913937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = 90000\nembedding_dim = 64\nmax_length = 100\ntrunc_type = 'post'\npadding_type = 'post'\noov_tok = '<OOV>'","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:48.056512Z","iopub.execute_input":"2022-04-26T23:51:48.05677Z","iopub.status.idle":"2022-04-26T23:51:48.060635Z","shell.execute_reply.started":"2022-04-26T23:51:48.056733Z","shell.execute_reply":"2022-04-26T23:51:48.059954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(train_text)\nword_index = tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:50.196282Z","iopub.execute_input":"2022-04-26T23:51:50.196934Z","iopub.status.idle":"2022-04-26T23:51:52.228567Z","shell.execute_reply.started":"2022-04-26T23:51:50.196896Z","shell.execute_reply":"2022-04-26T23:51:52.227795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sequences = tokenizer.texts_to_sequences(train_text)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:53.278421Z","iopub.execute_input":"2022-04-26T23:51:53.278988Z","iopub.status.idle":"2022-04-26T23:51:54.69371Z","shell.execute_reply.started":"2022-04-26T23:51:53.278948Z","shell.execute_reply":"2022-04-26T23:51:54.692985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:56.423475Z","iopub.execute_input":"2022-04-26T23:51:56.423727Z","iopub.status.idle":"2022-04-26T23:51:56.995221Z","shell.execute_reply.started":"2022-04-26T23:51:56.4237Z","shell.execute_reply":"2022-04-26T23:51:56.99447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w = train['tokenized_text']\nl = []\nfor i in w:\n    l.append(len(i))\nimport statistics\nstatistics.mean(l)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:13:27.191547Z","iopub.execute_input":"2022-04-26T23:13:27.191917Z","iopub.status.idle":"2022-04-26T23:13:27.36173Z","shell.execute_reply.started":"2022-04-26T23:13:27.191882Z","shell.execute_reply":"2022-04-26T23:13:27.36071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sequences = tokenizer.texts_to_sequences(test_text)\ntest_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:51:59.577802Z","iopub.execute_input":"2022-04-26T23:51:59.57844Z","iopub.status.idle":"2022-04-26T23:52:00.079582Z","shell.execute_reply.started":"2022-04-26T23:51:59.578393Z","shell.execute_reply":"2022-04-26T23:52:00.078836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_tokenizer = Tokenizer()\nlabel_tokenizer.fit_on_texts(df_new['discourse_type'].str.replace(' ', ''))\n\ntraining_label_seq = np.array(label_tokenizer.texts_to_sequences(train_lab.str.replace(' ', '')))\ntest_label_seq = np.array(label_tokenizer.texts_to_sequences(test_lab.str.replace(' ', '')))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:52:02.431782Z","iopub.execute_input":"2022-04-26T23:52:02.432513Z","iopub.status.idle":"2022-04-26T23:52:04.897231Z","shell.execute_reply.started":"2022-04-26T23:52:02.432473Z","shell.execute_reply":"2022-04-26T23:52:04.896476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_label_final = training_label_seq - 1\ntest_label_final = test_label_seq - 1","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:52:06.254962Z","iopub.execute_input":"2022-04-26T23:52:06.255731Z","iopub.status.idle":"2022-04-26T23:52:06.260373Z","shell.execute_reply.started":"2022-04-26T23:52:06.255684Z","shell.execute_reply":"2022-04-26T23:52:06.259621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(train_label_final)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:52:07.958993Z","iopub.execute_input":"2022-04-26T23:52:07.959776Z","iopub.status.idle":"2022-04-26T23:52:07.97096Z","shell.execute_reply.started":"2022-04-26T23:52:07.959735Z","shell.execute_reply":"2022-04-26T23:52:07.970199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\ndef reset_seeds():\n    np.random.seed(123) \n    random.seed(123)\n    tf.random.set_seed(123)\n\nreset_seeds()\n\nmodel = tf.keras.Sequential([\n    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n#    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    # use ReLU in place of tanh function since they are very good alternatives of each other.\n    tf.keras.layers.Dense(embedding_dim, activation='relu')\n    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n    tf.keras.layers.Dense(7, activation='softmax')\n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T00:02:33.591885Z","iopub.execute_input":"2022-04-27T00:02:33.592149Z","iopub.status.idle":"2022-04-27T00:02:34.029975Z","shell.execute_reply.started":"2022-04-27T00:02:33.592121Z","shell.execute_reply":"2022-04-27T00:02:34.029154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nnum_epochs = 3\nhistory = model.fit(train_padded, train_label_final, epochs=num_epochs, validation_data=(test_padded, test_label_final), verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T00:02:43.987727Z","iopub.execute_input":"2022-04-27T00:02:43.988026Z","iopub.status.idle":"2022-04-27T00:06:12.266924Z","shell.execute_reply.started":"2022-04-27T00:02:43.987994Z","shell.execute_reply":"2022-04-27T00:06:12.266199Z"},"trusted":true},"execution_count":null,"outputs":[]}]}